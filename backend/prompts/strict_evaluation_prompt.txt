STRICT EVALUATION PROMPT (AUTOMAT, COMPACT ENGLISH, BOOLEAN/0/1/NULL CHECKS)


Aim: Evaluate the provided README strictly against the defined taxonomy and produce ONLY a valid JSON that conforms exactly to the canonical structure and the strict JSON Schema. Use the README text only. If information is missing, mark checklist items using boolean/0/1/NULL rules. Include short literal evidence snippets with line numbers (e.g., “L0023: ...”) when an item is present. No creativity, no explanations, no text outside JSON.


Users: Auditors and automated systems requiring deterministic, schema-valid JSON with traceable evidence.


Task: Read the line-numbered README. Fill all required fields of the JSON output exactly per the canonical schema. Checklist fields use boolean/0/1/NULL as follows:


 * Presence/Yes → 1
 * Absence/No → 0
 * Not applicable → NULL
   Quality scores must be integers 1–5. Evidence strings must be literal substrings cited from the README, preferably with line tags. If a claim cannot be supported by a literal substring, mark the corresponding checklist 0 (or NULL if truly not applicable). Return ONLY the final JSON.


Output: A single JSON object that:


 * Matches the canonical structure (keys, nesting, arrays, objects).
 * Validates against the strict JSON Schema.
 * Uses checklist values strictly as 0, 1, or NULL.
 * Uses 1–5 integers for all quality scores.
 * Includes short literal evidence lines where applicable.
 * Contains concise observations based ONLY on the README.
   Prohibited: any text outside JSON, commentary, or extra fields.


Method: Follow instructions literally; temperature should be “cold”. Use only README content. Prefer conservative judgments: if unsure and no literal evidence, use 0 or NULL (not applicable). Do not add fields not defined by the schema. Ensure all required fields exist. Evidence must be short literal excerpts; include “Lxxxx:” when possible.


Assessment: The JSON must parse, satisfy all required fields and types, enforce checklist values in {0,1,NULL}, and quality scores in [1..5]. Evidence must be found as substrings of the README. No content outside JSON.


Traceability: Canonical structure (for shape reference) and strict schema (for constraints) are shown below. Follow them exactly. After that, the example README content is provided.


----------------------------------------


Canonical structure (schemas/taxonomia.json; condensed for shape)


{
  "metadata": {
    "repository_name": "",
    "repository_link": "",
    "readme_raw_link": "",
    "evaluation_date": "",
    "evaluator": "",
    "general_notes": ""
  },
  "structural_summary": {
    "detected_sections": [],
    "present_categories": {
      "what": "", "why": "", "how_installation": "", "how_usage": "",
      "how_config_requirements": "", "when": "", "who": "",
      "license": "", "contribution": "", "references": "", "other": ""
    },
    "organization_notes": ""
  },
  "categories": { /* condensed - follow schema/taxonomia.json exactly */ }
}


----------------------------------------


Strict schema (schemas/taxonomia.schema.json; constraints summary)


 * Top-level required keys: metadata, structural_summary, categories, dimensions_summary, executive_summary
 * All objects: "additionalProperties": false
 * Checklists: each key must be one of 0, 1, or NULL
 * Quality fields: integers 1..5
 * Arrays of strings for evidencias/justificativas/melhorias_sugeridas
 * Boolean flags in other.acao
   Note: You must format checklist fields as numbers or null in the final JSON. Do not use symbols.


----------------------------------------


Example README (numbered; provide your README content here after this section)

L0001: # Example Title
L0002: ...


----------------------------------------


Return ONLY the JSON.


----------------------------------------
